# Multimodal and Multilingual NLI Dataset

This repository accompanies our Interspeech 2025 paper:  
**"Beyond Similarity Scoring: Detecting Entailment and Contradiction in Multilingual and Multimodal Contexts"**  
by *Othman Istaiteh, Salima Mdhaffar, Yannick Est√®ve*

## üìå Dataset Overview

This dataset supports multilingual and multimodal Natural Language Inference (NLI), enabling the classification of entailment, contradiction, and neutrality across four modality pairs: text-text, text-speech, speech-text, and speech-speech. It covers Arabic, English, and French, facilitating research beyond traditional similarity scoring methods by detecting logical relationships in both text and speech across multiple languages.

- **4 Modality Combinations**:
  - Text-Text (T-T)
  - Text-Speech (T-S)
  - Speech-Text (S-T) 
  - Speech-Speech (S-S)
  
- **Label System**:
  - `0` = Entailment
  - `1` = Contradiction  
  - `2` = Neutral

## üìÇ Dataset Directory Structure
```
dataset/
‚îú‚îÄ‚îÄ audio/
‚îÇ   ‚îú‚îÄ‚îÄ fleurs/
‚îÇ   ‚îî‚îÄ‚îÄ tts_generated/
‚îú‚îÄ‚îÄ dev.csv
‚îú‚îÄ‚îÄ test.csv
‚îî‚îÄ‚îÄ train.csv
```

### üìù Data Composition

| Source Type          | Description                                                                 | Examples                     |
|----------------------|-----------------------------------------------------------------------------|------------------------------|
| **XNLI**             | Human-annotated text pairs (15 languages)                                   | Text-text pairs              |
| **SNLI**             | English image-caption derived NLI pairs                                     | Text-text pairs              |  
| **FLEURS**           | Natural speech recordings with transcriptions                               | Speech-text pairs            |
| **TTS_generated**    | Synthetic speech from VITS multispeaker model (English only)                 | Speech-text, speech-speech   |
| **Mistral_generated**| NLI pairs generated by fine-tuned Mistral 7B                                | Text-text pairs              |

### üìä CSV File Specifications

Each CSV contains these columns:

| Column                  | Description                                                                 | Possible Values                              |
|-------------------------|-----------------------------------------------------------------------------|----------------------------------------------|
| `premise`               | Text content or audio path                                                  | String (text) or path (e.g. `audio/tts_generated/en_tts_dev_0.wav`) |
| `hypothesis`            | Text content or audio path                                                  | Same as premise                              |
| `label`                 | Relationship classification                                                 | `0` (entail), `1` (contradict), `2` (neutral) |
| `premise_modality`      | Data type of premise                                                        | `text` or `speech`                           |
| `hypothesis_modality`   | Data type of hypothesis                                                     | `text` or `speech`                           |
| `premise_language`      | Language of premise                                                         | `en`, `fr`, `ar`                             |
| `hypothesis_language`   | Language of hypothesis                                                      | `en`, `fr`, `ar`                             |
| `premise_source`        | Origin of premise data                                                      | `XNLI`, `SNLI`, `FLEURS`, `TTS_generated`, `Mistral_generated` |
| `hypothesis_source`     | Origin of hypothesis data                                                   | Same as premise_source                       |

## üì• Audio Data Download Instructions

1. Download audio components:
   - [FLEURS recordings](https://drive.google.com/drive/folders/1epNXU_WdzcLrLN7xI9WUgCYCyhg8dw-R)
   - [TTS-generated speech (English only)](https://drive.google.com/drive/folders/1sYs46xvymAelD807kVdyEgmv9vea-15B)

2. Place the downloaded files in the `audio/` directory maintaining the folder structure.

3. You may need to replace the relative path `audio/` with the full absolute path for premise and hypothesis audio files in the CSVs.

## ‚öñÔ∏è License

This dataset combines:

- SNLI ([CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/))  
- XNLI ([CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/))  
- FLEURS ([CC BY 4.0](https://creativecommons.org/licenses/by/4.0/))  

The dataset as a whole is licensed under **CC BY-NC 4.0**, which is the most restrictive license among the components. It requires:

- Attribution  
- Non-commercial use  
- Share-alike (derivatives must use the same license)

## üìñ Citation

If you use this dataset, please cite our paper:

```bibtex
@inproceedings{istaiteh2025beyond,
  title={Beyond Similarity Scoring: Detecting Entailment and Contradiction in Multilingual and Multimodal Contexts},
  author={Istaiteh, Othman and Mdhaffar, Salima and Est√®ve, Yannick},
  booktitle={Interspeech 2025, Accepted Paper},
  year={2025}
}
```

## üèõÔ∏è Affiliations

This work was conducted at [LIA Lab](https://lia.univ-avignon.fr/),  
part of [Universit√© d‚ÄôAvignon](https://univ-avignon.fr/).

## üì¨ Contact

For questions, suggestions, or collaboration inquiries, please contact:

**Othman Istaiteh**  
Email: othmanistaiteh@gmail.com

Feel free to open issues or pull requests on this repository.
